{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:42.745488Z",
     "start_time": "2024-11-18T08:27:42.103824Z"
    }
   },
   "source": [
    "import torch\n",
    "from gpt import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,    #1\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,       #2\n",
    "    \"qkv_bias\": False,\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.285973Z",
     "start_time": "2024-11-18T08:27:42.750035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "from gpt import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)    #1\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)                #2\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ],
   "id": "f9bef1b5aabe1a86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.297263Z",
     "start_time": "2024-11-18T08:27:43.294247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "inputs"
   ],
   "id": "4e23f735cd819438",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16833,  3626,  6100],\n",
       "        [   40,  1107,   588]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.326911Z",
     "start_time": "2024-11-18T08:27:43.324892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]])  #  \" really like chocolate\"]"
   ],
   "id": "93b40a39a7279327",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.401743Z",
     "start_time": "2024-11-18T08:27:43.356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():     #1\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)     #2\n",
    "print(probas.shape)\n",
    "probas"
   ],
   "id": "6ab7564d4a20c648",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05,\n",
       "          6.9776e-06, 1.8776e-05],\n",
       "         [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05,\n",
       "          6.0103e-06, 1.3571e-05],\n",
       "         [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05,\n",
       "          1.4094e-05, 1.3526e-05]],\n",
       "\n",
       "        [[1.2561e-05, 2.0538e-05, 1.4332e-05,  ..., 1.0389e-05,\n",
       "          3.4784e-05, 1.4239e-05],\n",
       "         [7.2731e-06, 1.7864e-05, 1.0565e-05,  ..., 2.1206e-05,\n",
       "          1.1390e-05, 1.5559e-05],\n",
       "         [2.9496e-05, 3.3605e-05, 4.1029e-05,  ..., 6.5249e-06,\n",
       "          5.8203e-05, 1.3698e-05]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.411526Z",
     "start_time": "2024-11-18T08:27:43.409044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)    #3\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ],
   "id": "9362ed806631674b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.422016Z",
     "start_time": "2024-11-18T08:27:43.419479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "\n",
    "for i in range(3):\n",
    "    print(token_ids_to_text(token_ids[0, i].unsqueeze(0), tokenizer))"
   ],
   "id": "a1f691c4a9f44902",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n",
      " Armed\n",
      " he\n",
      "Netflix\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.432014Z",
     "start_time": "2024-11-18T08:27:43.429695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [['hello'], ['world']][0, 0]\n",
    "slice(0, 1)"
   ],
   "id": "254b8aa146257d14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(0, 1, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.443302Z",
     "start_time": "2024-11-18T08:27:43.439602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "# print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "print(probas.shape)\n",
    "print(\"targets[text_idx]\", targets[text_idx])\n",
    "print(probas[text_idx, [0, 1, 2]])\n",
    "print(probas[text_idx, [0, 1, 2], [3626, 6100, 345]])\n",
    "\n",
    "# text_idx = 1\n",
    "# print(\"targets[text_idx]\", targets[text_idx])\n",
    "# target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "# print(\"Text 2:\", target_probas_2)"
   ],
   "id": "5864d2f1fc358794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "targets[text_idx] tensor([3626, 6100,  345])\n",
      "tensor([[1.8849e-05, 1.5172e-05, 1.1687e-05,  ..., 2.2409e-05, 6.9776e-06,\n",
      "         1.8776e-05],\n",
      "        [9.1569e-06, 1.0062e-05, 7.8786e-06,  ..., 2.9090e-05, 6.0103e-06,\n",
      "         1.3571e-05],\n",
      "        [2.9877e-05, 8.8507e-06, 1.5741e-05,  ..., 3.5456e-05, 1.4094e-05,\n",
      "         1.3526e-05]])\n",
      "tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.453217Z",
     "start_time": "2024-11-18T08:27:43.450021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ],
   "id": "16d9261baa904887",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.462759Z",
     "start_time": "2024-11-18T08:27:43.460120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ],
   "id": "d57fbc8fa6585951",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.471677Z",
     "start_time": "2024-11-18T08:27:43.469382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ],
   "id": "e2e177dad5a9563e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.480436Z",
     "start_time": "2024-11-18T08:27:43.478150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "neg_avg_log_probas = -avg_log_probas\n",
    "print(neg_avg_log_probas)"
   ],
   "id": "ceab2f1686ec7761",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.489285Z",
     "start_time": "2024-11-18T08:27:43.487211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ],
   "id": "d1365624443a77a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.498700Z",
     "start_time": "2024-11-18T08:27:43.496336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ],
   "id": "d069b4474ee425c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.508770Z",
     "start_time": "2024-11-18T08:27:43.505881Z"
    }
   },
   "cell_type": "code",
   "source": "print(logits_flat)",
   "id": "21d13a4c088e0699",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1113, -0.1057, -0.3666,  ...,  0.2843, -0.8824,  0.1074],\n",
      "        [-0.6109, -0.5167, -0.7613,  ...,  0.5450, -1.0319, -0.2175],\n",
      "        [ 0.5707, -0.6459, -0.0701,  ...,  0.7419, -0.1806, -0.2217],\n",
      "        [-0.2968,  0.1949, -0.1649,  ..., -0.4867,  0.7218, -0.1714],\n",
      "        [-0.8375,  0.0612, -0.4641,  ...,  0.2327, -0.3889, -0.0770],\n",
      "        [ 0.5614,  0.6919,  0.8915,  ..., -0.9472,  1.2411, -0.2056]])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.518510Z",
     "start_time": "2024-11-18T08:27:43.516057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ],
   "id": "7651bacc8ffa64c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.527921Z",
     "start_time": "2024-11-18T08:27:43.525832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ],
   "id": "1faba88b2c10ea86",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.538885Z",
     "start_time": "2024-11-18T08:27:43.535188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ],
   "id": "59da2a9e888b3acc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:43.548229Z",
     "start_time": "2024-11-18T08:27:43.546338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ],
   "id": "b4db00e29424d856",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:53.686875Z",
     "start_time": "2024-11-18T08:27:53.681219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ],
   "id": "b715a05a666c7666",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T08:27:59.115039Z",
     "start_time": "2024-11-18T08:27:59.111729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ],
   "id": "b756ca388b2ffc9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:24:57.522191Z",
     "start_time": "2024-11-18T09:24:57.520034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)         #1\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    print(logits)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ],
   "id": "2db6439b373282c5",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:09:57.128762Z",
     "start_time": "2024-11-18T09:09:57.125878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)     #1\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))   #2\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()    #3\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches    #4"
   ],
   "id": "f2e1ee203e804fd7",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:11:43.057549Z",
     "start_time": "2024-11-18T09:11:40.884516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)   #1\n",
    "with torch.no_grad():                                        #2\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)    #3\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ],
   "id": "cde4324942e78817",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583584255642\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:14:33.017251Z",
     "start_time": "2024-11-18T09:14:33.012390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []    #1\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):    #2\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()   #3\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()                     #4\n",
    "            optimizer.step()                    #5\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:    #6\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(                      #7\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  #1\n",
    "    with torch.no_grad():                              #2\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "            )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))      #1\n",
    "    model.train()"
   ],
   "id": "d7ac0bd0f1a9ed56",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T09:25:08.862305Z",
     "start_time": "2024-11-18T09:25:02.524047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),           #1\n",
    "lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 20\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ],
   "id": "b82cd5c2754a6657",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2083,  0.4924, -0.3442,  ..., -0.5408, -0.2499, -0.3587],\n",
      "         [-0.4501,  0.0952, -1.0981,  ...,  0.3667,  0.2857,  0.7341],\n",
      "         [ 1.1160,  0.1036,  0.0369,  ..., -0.4808, -0.1055, -0.0417],\n",
      "         ...,\n",
      "         [-0.3095, -0.4304,  0.3218,  ...,  0.5655,  0.6497, -0.0139],\n",
      "         [ 0.0859, -0.3715, -0.5812,  ..., -0.3215,  0.4776,  0.3006],\n",
      "         [-0.1932, -0.0869,  0.3103,  ..., -0.0259,  0.0153, -0.4454]],\n",
      "\n",
      "        [[-0.8230,  0.4825, -1.2794,  ..., -0.7179, -0.2440,  0.5285],\n",
      "         [-0.7859,  0.2965, -0.8009,  ..., -0.1119, -0.3239,  0.2372],\n",
      "         [ 0.9691,  0.4552, -0.1307,  ..., -0.1205,  0.5430,  0.4855],\n",
      "         ...,\n",
      "         [-0.0647, -0.4918,  0.6872,  ...,  0.3854,  0.2371,  0.4129],\n",
      "         [-0.5338, -0.1936, -0.5402,  ..., -0.4132, -0.4543,  0.3886],\n",
      "         [ 0.4272, -0.4158, -0.5000,  ..., -0.1093, -0.3311, -0.4624]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[ 0.0174, -0.0288,  0.8723,  ...,  0.8139, -0.4911, -1.4805],\n",
      "         [-0.9494,  0.0801,  0.5973,  ...,  0.0562,  0.2549, -1.1826],\n",
      "         [ 0.4376, -0.0307,  0.7430,  ...,  0.2266, -0.1028, -1.1992],\n",
      "         ...,\n",
      "         [-0.4283, -0.5468,  0.7475,  ...,  0.4695,  0.4152, -0.9461],\n",
      "         [-0.2608, -0.0591,  0.0209,  ..., -0.4233,  0.3305, -0.7491],\n",
      "         [ 0.1112, -0.2404,  0.4349,  ..., -0.3031,  0.3425, -0.5641]],\n",
      "\n",
      "        [[-0.4949,  0.0168, -0.0164,  ...,  0.4582, -0.2875, -0.2079],\n",
      "         [-0.7795,  0.3370,  0.7414,  ...,  0.3195,  0.0770, -0.6895],\n",
      "         [ 0.3183, -0.5005,  0.5535,  ...,  0.2413,  0.6819, -0.9970],\n",
      "         ...,\n",
      "         [ 0.0465, -0.4546,  0.4152,  ...,  0.1083,  0.8936, -1.1380],\n",
      "         [-0.1821, -0.0392, -0.2409,  ..., -0.6288,  0.4555, -0.3826],\n",
      "         [-0.2886,  0.0167,  0.6991,  ..., -0.3119,  0.2926, -1.1252]]])\n",
      "tensor([[[-0.8746, -0.1294,  0.5905,  ...,  0.2603, -0.3969, -1.3690],\n",
      "         [-0.8929,  0.2765,  0.7151,  ...,  0.5564, -0.0598, -1.5360],\n",
      "         [ 0.3685, -0.0625,  0.3906,  ..., -0.0736,  0.2245, -1.1875],\n",
      "         ...,\n",
      "         [-0.4089, -0.0410,  0.5686,  ...,  0.3244,  0.6726, -0.7422],\n",
      "         [ 0.1779,  0.0528,  0.3557,  ..., -0.1046, -0.0371, -0.3319],\n",
      "         [ 0.1527, -0.1129,  0.3979,  ...,  0.5816, -0.1365, -0.7822]],\n",
      "\n",
      "        [[-0.3518, -0.2380,  0.7687,  ...,  0.3615, -0.4516, -0.7159],\n",
      "         [-0.5118,  0.1246,  0.4353,  ...,  0.7416, -0.6006, -1.0774],\n",
      "         [ 0.4302, -0.1947,  0.9938,  ..., -0.0783,  0.0022, -1.3508],\n",
      "         ...,\n",
      "         [-0.2020, -0.2907,  0.7372,  ...,  0.5659,  0.3820, -0.7151],\n",
      "         [ 0.2727,  0.0818, -0.0381,  ..., -0.4740,  0.4494, -0.0362],\n",
      "         [-0.2212,  1.8520,  0.5269,  ..., -0.3727, -0.2657, -0.6611]]])\n",
      "tensor([[[ 0.1006, -0.1507,  0.7154,  ...,  0.3293, -0.3086, -1.3032],\n",
      "         [-0.2632,  0.2532,  0.2369,  ...,  0.4271,  0.0810, -0.5108],\n",
      "         [ 0.5635, -0.0860,  0.6926,  ...,  0.1774, -0.1887, -1.1161],\n",
      "         ...,\n",
      "         [-0.4242, -0.2989,  1.0576,  ...,  0.4667,  0.7214, -0.6958],\n",
      "         [-0.1503, -0.0698,  0.2398,  ..., -0.2586,  0.3935, -0.7368],\n",
      "         [-0.1938, -0.0649,  0.7609,  ...,  0.0185,  0.2589, -0.9876]],\n",
      "\n",
      "        [[-0.1946, -0.0383,  0.3594,  ...,  0.9256,  0.0394, -1.0939],\n",
      "         [-0.6422,  0.1427,  0.5618,  ...,  0.5653,  0.5550, -0.4875],\n",
      "         [ 0.1791,  0.3705,  0.7772,  ..., -0.3500,  0.5796, -1.3671],\n",
      "         ...,\n",
      "         [-0.3717, -0.3295,  0.9832,  ...,  0.2768,  0.1881, -0.3941],\n",
      "         [ 0.3490, -0.0394,  0.5304,  ..., -0.2057, -0.1104,  0.4922],\n",
      "         [-0.0527,  0.1109,  0.6227,  ...,  0.1313,  0.0433, -0.2244]]])\n",
      "tensor([[[-0.3573, -0.0727,  0.2658,  ...,  0.6266, -0.1699, -1.3861],\n",
      "         [-0.5474,  0.4620,  0.4494,  ...,  0.3875, -0.6008, -1.1645],\n",
      "         [ 0.3812, -0.0276,  0.7581,  ..., -0.0970,  0.1021, -0.8003],\n",
      "         ...,\n",
      "         [-0.2885,  0.5771,  0.7721,  ...,  0.4242,  0.5054, -0.9849],\n",
      "         [-0.0314,  0.4250,  0.2978,  ..., -0.2101,  0.6383, -0.3389],\n",
      "         [ 0.1116, -0.6556,  0.5227,  ...,  0.2848, -0.0760, -1.2741]],\n",
      "\n",
      "        [[ 0.1182, -0.0715,  0.6565,  ...,  0.2265,  0.2834, -0.7319],\n",
      "         [-0.3544, -0.0837,  0.6894,  ...,  0.2991,  0.0885, -0.7764],\n",
      "         [ 0.6564,  0.1007,  0.7833,  ..., -0.2489,  0.0765, -1.0362],\n",
      "         ...,\n",
      "         [ 0.1921, -0.7080,  1.1173,  ...,  0.2308,  0.7354, -0.6966],\n",
      "         [ 0.1325,  0.1934,  0.4586,  ..., -0.1052, -0.0382, -0.4384],\n",
      "         [ 0.1128,  0.2117,  0.6056,  ...,  0.0561,  0.2432, -1.0507]]])\n",
      "tensor([[[-0.1807, -0.3373,  0.8352,  ...,  0.3104,  0.2444, -1.1212],\n",
      "         [-0.7009,  0.1744,  0.8141,  ..., -0.0616,  0.2026, -0.8838],\n",
      "         [ 0.5923,  0.0128,  1.0576,  ..., -0.2850, -0.0158, -1.0556],\n",
      "         ...,\n",
      "         [-0.5776, -0.5158,  0.6046,  ...,  0.0784,  0.3833, -1.0470],\n",
      "         [-0.3003,  0.3231,  0.1556,  ..., -0.1833,  0.6513, -0.2683],\n",
      "         [ 0.2092, -0.1201,  0.4529,  ..., -0.1886,  0.0393, -0.6562]],\n",
      "\n",
      "        [[-0.6196,  0.0972,  0.4055,  ...,  0.7738, -0.7805, -1.4085],\n",
      "         [-0.5895,  0.3311,  0.6608,  ...,  0.1488, -0.1440, -1.2741],\n",
      "         [ 0.1778, -0.4415,  0.9934,  ...,  0.4034,  0.0261, -1.8499],\n",
      "         ...,\n",
      "         [ 0.1760, -0.7455,  0.7499,  ...,  0.3906,  0.6565, -0.8061],\n",
      "         [-0.0737,  0.2974,  0.1772,  ..., -0.5360,  0.4958, -1.0420],\n",
      "         [-0.1101, -0.3992,  0.0718,  ..., -0.1034,  0.2086, -0.8820]]])\n",
      "tensor([[[-0.1059, -0.0655,  0.3270,  ...,  0.3758, -0.4822, -1.0228],\n",
      "         [-0.5207,  0.3217,  0.1167,  ..., -0.0399, -0.0241, -1.0471],\n",
      "         [ 0.6884,  0.0096,  0.8632,  ..., -0.1670,  0.1194, -1.1971],\n",
      "         ...,\n",
      "         [-0.2976, -0.6006,  0.9792,  ..., -0.0989,  0.4017, -1.1172],\n",
      "         [-0.5494, -0.0760,  0.5373,  ..., -0.0528,  0.4043, -0.5883],\n",
      "         [-0.1227,  0.1382,  0.3247,  ...,  0.1031,  0.0985, -1.2365]],\n",
      "\n",
      "        [[-0.2822, -0.0561,  0.4097,  ...,  0.2846, -0.1439, -0.6417],\n",
      "         [-0.4917, -0.1371,  0.8103,  ...,  0.3319,  0.0279, -1.4840],\n",
      "         [-0.1977, -0.3657,  0.9177,  ...,  0.0987, -0.0599, -0.9848],\n",
      "         ...,\n",
      "         [-0.2990, -0.3204,  1.1113,  ..., -0.0384,  0.4030, -0.9127],\n",
      "         [ 0.1954,  0.1397,  0.9792,  ..., -0.4017,  0.7096,  0.1534],\n",
      "         [-0.1394, -0.3312,  0.9084,  ...,  0.6663,  0.0518, -1.5395]]])\n",
      "Ep 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
      "tensor([[[-0.4056,  0.4562,  0.4104,  ...,  0.8349, -0.5910, -1.2563],\n",
      "         [-0.5617,  0.3562,  0.5694,  ...,  0.0283, -0.1935, -1.3588],\n",
      "         [ 0.4099, -0.4104,  0.9686,  ...,  0.3623, -0.0734, -1.7352],\n",
      "         ...,\n",
      "         [ 0.1424, -0.8450,  0.5161,  ...,  0.5279,  0.5865, -0.8305],\n",
      "         [ 0.1314,  0.2675,  0.1238,  ..., -0.6444,  0.3171, -0.9171],\n",
      "         [ 0.0218, -0.0731,  0.1544,  ..., -0.1935,  0.0150, -0.9587]],\n",
      "\n",
      "        [[-0.0472, -0.0784,  0.5538,  ...,  0.5470, -0.3462, -0.7001],\n",
      "         [-0.0893, -0.0435,  0.1275,  ...,  0.5485, -0.7100, -1.1542],\n",
      "         [ 0.2097, -0.2424,  0.8972,  ..., -0.0091,  0.1532, -1.2777],\n",
      "         ...,\n",
      "         [-0.3384, -0.1313,  0.7014,  ...,  0.6070,  0.4513, -0.6111],\n",
      "         [ 0.2897,  0.0560, -0.0178,  ..., -0.6777,  0.5513, -0.2108],\n",
      "         [-0.0947,  1.5816,  0.7940,  ..., -0.1548, -0.3958, -0.5371]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[ 0.2774,  0.5392,  0.5696,  ..., -0.4909, -0.1057, -1.5252],\n",
      "         [ 0.5182,  0.8514,  0.2614,  ..., -0.4370,  0.1663, -1.0214],\n",
      "         [ 0.5868,  0.7002,  0.0803,  ..., -0.6300,  0.1904, -1.1691],\n",
      "         ...,\n",
      "         [ 0.2477,  0.8643,  0.0913,  ..., -0.4004,  0.1186, -0.8922],\n",
      "         [ 0.5676,  0.9258, -0.0847,  ..., -0.5448,  0.3262, -0.8584],\n",
      "         [ 0.1643,  0.7573,  0.3865,  ..., -0.4503,  0.3418, -1.1358]],\n",
      "\n",
      "        [[ 0.0325,  0.5801, -0.1384,  ..., -0.2144,  0.2772, -1.1820],\n",
      "         [-0.0364,  0.7391,  0.1163,  ..., -0.0277, -0.0191, -1.2410],\n",
      "         [ 0.7487,  0.7878,  0.5177,  ..., -0.4693,  0.1662, -0.8345],\n",
      "         ...,\n",
      "         [-0.1782,  0.4608,  0.3620,  ..., -0.3042,  0.1653, -1.0674],\n",
      "         [ 0.2781,  1.1708,  0.1435,  ..., -0.5783,  0.3640, -0.4582],\n",
      "         [ 0.3267,  0.9975,  0.0113,  ..., -0.3861,  0.3741, -1.0618]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[ 0.1573,  1.2377,  0.2098,  ..., -0.7446, -0.2202, -1.4133],\n",
      "         [ 0.0119,  1.3915,  0.1698,  ..., -0.6810, -0.0238, -1.5286],\n",
      "         [ 0.3384,  1.3285, -0.0409,  ..., -0.7188,  0.0385, -1.3372],\n",
      "         ...,\n",
      "         [-0.0050,  1.3372,  0.1196,  ..., -0.7283,  0.2418, -1.1219],\n",
      "         [ 0.1562,  1.3466,  0.0574,  ..., -0.7652, -0.1079, -1.1990],\n",
      "         [ 0.1939,  1.2726, -0.1162,  ..., -0.5683, -0.1925, -1.1117]],\n",
      "\n",
      "        [[ 0.5663,  1.4364,  0.1825,  ..., -0.7478, -0.2499, -1.1708],\n",
      "         [ 0.0206,  1.4563, -0.1441,  ..., -0.8542, -0.1758, -1.2413],\n",
      "         [ 0.5043,  1.3931,  0.1940,  ..., -0.9938, -0.1490, -1.4463],\n",
      "         ...,\n",
      "         [-0.0699,  1.2284,  0.2130,  ..., -0.8371,  0.3336, -1.0088],\n",
      "         [-0.0345,  1.6843, -0.0104,  ..., -0.6952,  0.2138, -1.2220],\n",
      "         [ 0.2071,  1.3803,  0.1038,  ..., -0.5514,  0.0847, -0.9421]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[ 7.4804e-01,  1.2405e+00, -2.1334e-02,  ..., -4.7383e-01,\n",
      "          -3.4963e-02, -1.9779e+00],\n",
      "         [ 6.6899e-01,  1.3637e+00, -1.0629e-01,  ..., -6.9506e-01,\n",
      "          -3.7281e-02, -1.5381e+00],\n",
      "         [ 8.3678e-01,  1.3089e+00, -7.4222e-03,  ..., -7.7085e-01,\n",
      "          -1.5992e-01, -1.8674e+00],\n",
      "         ...,\n",
      "         [ 3.7811e-01,  9.9037e-01, -2.5080e-01,  ..., -7.5594e-01,\n",
      "           2.4805e-01, -1.6064e+00],\n",
      "         [ 4.0081e-01,  1.1759e+00, -9.2969e-02,  ..., -6.9475e-01,\n",
      "           5.1791e-02, -1.7130e+00],\n",
      "         [ 5.2601e-01,  1.1700e+00, -2.7445e-01,  ..., -6.1638e-01,\n",
      "          -5.4357e-02, -1.6542e+00]],\n",
      "\n",
      "        [[ 6.4668e-01,  1.0254e+00, -1.7531e-01,  ..., -5.5079e-01,\n",
      "          -5.4712e-02, -1.6833e+00],\n",
      "         [ 5.6296e-01,  1.2764e+00, -7.9955e-02,  ..., -5.5431e-01,\n",
      "           6.6415e-02, -1.5401e+00],\n",
      "         [ 7.7810e-01,  1.2950e+00, -1.4398e-01,  ..., -8.1969e-01,\n",
      "          -7.7427e-04, -1.7474e+00],\n",
      "         ...,\n",
      "         [ 5.2371e-01,  9.8831e-01, -1.1295e-01,  ..., -6.8837e-01,\n",
      "           4.3402e-02, -1.3576e+00],\n",
      "         [ 6.4239e-01,  1.3578e+00, -8.6312e-02,  ..., -7.5358e-01,\n",
      "          -1.2796e-01, -1.1560e+00],\n",
      "         [ 5.8270e-01,  1.3677e+00, -1.6877e-01,  ..., -7.8045e-01,\n",
      "           5.3063e-02, -1.4508e+00]]], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[ 0.6938,  1.2648, -0.3810,  ..., -0.9820, -0.2292, -2.1482],\n",
      "         [ 0.8615,  2.5545, -0.3849,  ..., -1.1560, -0.3195, -1.9090],\n",
      "         [ 0.9357,  2.6674, -0.1526,  ..., -1.0858, -0.2122, -1.8283],\n",
      "         ...,\n",
      "         [ 0.6509,  1.0451, -0.4077,  ..., -0.6163, -0.0035, -1.9704],\n",
      "         [ 0.9163,  1.4043, -0.3098,  ..., -0.8863,  0.1203, -1.7613],\n",
      "         [ 0.8912,  1.2241, -0.3721,  ..., -0.9258, -0.0711, -1.8771]],\n",
      "\n",
      "        [[ 0.9262,  1.2208, -0.4976,  ..., -0.8103, -0.1442, -1.8242],\n",
      "         [ 0.9198,  1.3305, -0.2530,  ..., -0.7999, -0.0382, -1.9354],\n",
      "         [ 1.1776,  1.1422, -0.3515,  ..., -0.7803,  0.0168, -2.0706],\n",
      "         ...,\n",
      "         [ 0.7822,  0.9713, -0.3851,  ..., -0.8519,  0.1413, -2.0235],\n",
      "         [ 0.7609,  1.2569, -0.5231,  ..., -0.9939,  0.1488, -1.8744],\n",
      "         [ 0.6696,  1.2401, -0.2260,  ..., -0.9653,  0.0743, -1.9771]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "tensor([[[ 1.1048,  1.7221, -0.5349,  ..., -1.0709, -0.3935, -2.2321],\n",
      "         [ 1.1289,  1.8482, -0.6341,  ..., -1.0385, -0.3751, -2.2628],\n",
      "         [ 1.1841,  1.8255, -0.4971,  ..., -1.1688, -0.2688, -2.3217],\n",
      "         ...,\n",
      "         [ 0.9478,  1.6273, -0.5903,  ..., -0.9774, -0.1862, -2.1252],\n",
      "         [ 0.9729,  1.8200, -0.6848,  ..., -1.1938, -0.1493, -2.0294],\n",
      "         [ 0.9657,  3.5605, -0.4564,  ..., -1.3600, -0.4457, -1.9841]],\n",
      "\n",
      "        [[ 1.1125,  1.8487, -0.4373,  ..., -1.0585, -0.3782, -2.2582],\n",
      "         [ 1.0654,  1.8768, -0.6026,  ..., -1.0803, -0.2896, -2.1614],\n",
      "         [ 1.2308,  1.8351, -0.5352,  ..., -1.1233, -0.2970, -2.2882],\n",
      "         ...,\n",
      "         [ 0.9837,  1.7379, -0.5594,  ..., -1.1387, -0.1957, -2.1078],\n",
      "         [ 0.9528,  1.9004, -0.5669,  ..., -1.1381, -0.1767, -2.0408],\n",
      "         [ 0.9566,  1.7434, -0.5701,  ..., -1.1150, -0.2210, -2.2198]]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 9\u001B[0m\n\u001B[1;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdamW(\n\u001B[1;32m      5\u001B[0m      model\u001B[38;5;241m.\u001B[39mparameters(),           \u001B[38;5;66;03m#1\u001B[39;00m\n\u001B[1;32m      6\u001B[0m lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0004\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m\n\u001B[1;32m      7\u001B[0m )\n\u001B[1;32m      8\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m\n\u001B[0;32m----> 9\u001B[0m train_losses, val_losses, tokens_seen \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model_simple\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvery effort moves you\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[34], line 20\u001B[0m, in \u001B[0;36mtrain_model_simple\u001B[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001B[0m\n\u001B[1;32m     17\u001B[0m global_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_step \u001B[38;5;241m%\u001B[39m eval_freq \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:    \u001B[38;5;66;03m#6\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m     train_loss, val_loss \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[1;32m     23\u001B[0m     val_losses\u001B[38;5;241m.\u001B[39mappend(val_loss)\n",
      "Cell \u001B[0;32mIn[34], line 38\u001B[0m, in \u001B[0;36mevaluate_model\u001B[0;34m(model, train_loader, val_loader, device, eval_iter)\u001B[0m\n\u001B[1;32m     36\u001B[0m model\u001B[38;5;241m.\u001B[39meval()  \u001B[38;5;66;03m#1\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():                              \u001B[38;5;66;03m#2\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mcalc_loss_loader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_batches\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_iter\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m calc_loss_loader(\n\u001B[1;32m     42\u001B[0m         val_loader, model, device, num_batches\u001B[38;5;241m=\u001B[39meval_iter\n\u001B[1;32m     43\u001B[0m     )\n\u001B[1;32m     44\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n",
      "Cell \u001B[0;32mIn[30], line 11\u001B[0m, in \u001B[0;36mcalc_loss_loader\u001B[0;34m(data_loader, model, device, num_batches)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (input_batch, target_batch) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(data_loader):\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m<\u001B[39m num_batches:\n\u001B[0;32m---> 11\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mcalc_loss_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m         total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()    \u001B[38;5;66;03m#3\u001B[39;00m\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "Cell \u001B[0;32mIn[38], line 4\u001B[0m, in \u001B[0;36mcalc_loss_batch\u001B[0;34m(input_batch, target_batch, model, device)\u001B[0m\n\u001B[1;32m      2\u001B[0m input_batch \u001B[38;5;241m=\u001B[39m input_batch\u001B[38;5;241m.\u001B[39mto(device)         \u001B[38;5;66;03m#1\u001B[39;00m\n\u001B[1;32m      3\u001B[0m target_batch \u001B[38;5;241m=\u001B[39m target_batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 4\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(logits)\n\u001B[1;32m      6\u001B[0m loss \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mfunctional\u001B[38;5;241m.\u001B[39mcross_entropy(\n\u001B[1;32m      7\u001B[0m     logits\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m), target_batch\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[1;32m      8\u001B[0m )\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/gpt.py:31\u001B[0m, in \u001B[0;36mGPTModel.forward\u001B[0;34m(self, in_idx)\u001B[0m\n\u001B[1;32m     29\u001B[0m x \u001B[38;5;241m=\u001B[39m tok_embeds \u001B[38;5;241m+\u001B[39m pos_embeds\n\u001B[1;32m     30\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop_emb(x)\n\u001B[0;32m---> 31\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrf_blocks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_norm(x)\n\u001B[1;32m     33\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_head(x)\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/gpt.py:60\u001B[0m, in \u001B[0;36mTransformerBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     58\u001B[0m shortcut \u001B[38;5;241m=\u001B[39m x         \u001B[38;5;66;03m#3\u001B[39;00m\n\u001B[1;32m     59\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(x)\n\u001B[0;32m---> 60\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mff\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop_shortcut(x)\n\u001B[1;32m     62\u001B[0m x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m shortcut      \u001B[38;5;66;03m#4\u001B[39;00m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/gpt.py:76\u001B[0m, in \u001B[0;36mFeedForward.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/dev/LLM-hello-world/myenv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2f67460b6cc42e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
