{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-19T04:17:39.362630Z",
     "start_time": "2024-11-19T04:17:39.358071Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:                                                #1\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:17:47.509085Z",
     "start_time": "2024-11-19T04:17:47.150767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ],
   "id": "9d29f6f24dc61da7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:17:55.756052Z",
     "start_time": "2024-11-19T04:17:55.752939Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Example entry:\\n\", data[50])",
   "id": "5871312ce88fbc72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:18:09.482170Z",
     "start_time": "2024-11-19T04:18:09.479526Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Another example entry:\\n\", data[999])",
   "id": "484db7470c511139",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:19:33.284871Z",
     "start_time": "2024-11-19T04:19:33.282114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    )\n",
    "    return instruction_text + input_text"
   ],
   "id": "3e4afcc204258190",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:19:39.237995Z",
     "start_time": "2024-11-19T04:19:39.236062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ],
   "id": "1aeff19992ab4685",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:20:09.123042Z",
     "start_time": "2024-11-19T04:20:09.120186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ],
   "id": "9bbd39cb9b080743",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:20:20.642308Z",
     "start_time": "2024-11-19T04:20:20.639461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_portion = int(len(data) * 0.85)    #1\n",
    "test_portion = int(len(data) * 0.1)            #2\n",
    "val_portion = len(data) - train_portion - test_portion    #3\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ],
   "id": "f745abf56ef623ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:27:59.247725Z",
     "start_time": "2024-11-19T04:27:59.243345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:         #1\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ],
   "id": "488ef256bc7bd8c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:28:07.513766Z",
     "start_time": "2024-11-19T04:28:07.323685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ],
   "id": "9e846555bb85c33a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:31:56.162070Z",
     "start_time": "2024-11-19T04:31:56.159031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)   #1\n",
    "    inputs_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ],
   "id": "3eb616ee7e51bc36",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:32:43.867004Z",
     "start_time": "2024-11-19T04:32:43.863216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "print(custom_collate_draft_1(batch))"
   ],
   "id": "10771bf53e4ec190",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:34:16.507831Z",
     "start_time": "2024-11-19T04:34:16.503530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)   #1\n",
    "    inputs_lst = []\n",
    "    targets_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ],
   "id": "4a1b3cd1a64ed152",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:35:18.346635Z",
     "start_time": "2024-11-19T04:35:18.343629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"targets:\", targets)"
   ],
   "id": "8b31c4b95dca3de3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "targets: tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:37:23.006377Z",
     "start_time": "2024-11-19T04:37:23.001229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)   #1\n",
    "    inputs_lst = []\n",
    "    targets_lst = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1]:] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ],
   "id": "59fe8544be3f7bdb",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:37:54.278303Z",
     "start_time": "2024-11-19T04:37:54.273827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(\"inputs:\", inputs)\n",
    "print(\"targets:\", targets)"
   ],
   "id": "4e672cc5b655f188",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "targets: tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:41:26.830570Z",
     "start_time": "2024-11-19T04:41:26.827053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits_1 = torch.tensor(\n",
    "    [[-1.0, 1.0],\n",
    "     [-0.5, 1.5],\n",
    "     [-0.5, 1.5]]\n",
    ")\n",
    "targets_1 = torch.tensor([1, 0, -100])\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ],
   "id": "723cb4fdd7dd9b22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:41:55.529985Z",
     "start_time": "2024-11-19T04:41:55.526809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)"
   ],
   "id": "c7b967baebfd01ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:42:32.379909Z",
     "start_time": "2024-11-19T04:42:32.377083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    allowed_max_length=1024,\n",
    "    device=device\n",
    ")"
   ],
   "id": "1c6ded7cc04e94b4",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:44:35.386041Z",
     "start_time": "2024-11-19T04:44:35.351732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ],
   "id": "4b78174a5c7b7405",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:45:11.015791Z",
     "start_time": "2024-11-19T04:45:10.977078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ],
   "id": "fd9e809c01df896e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:48:03.732374Z",
     "start_time": "2024-11-19T04:48:03.727749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,    #1\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,       #2\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-medium (355M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ],
   "id": "5d01af06d7c515ed",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:56:02.265188Z",
     "start_time": "2024-11-19T04:48:04.122214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt import load_weights_into_gpt, GPTModel\n",
    "\n",
    "model_size = model_name.split(\" \")[-1].lstrip(\"(\").rstrip(')')\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(NEW_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ],
   "id": "b31d12bd3736880a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 44.0kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 959kiB/s] \n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 18.5kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [07:46<00:00, 3.04MiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 1.89MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 852kiB/s]  \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 628kiB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:56:53.224872Z",
     "start_time": "2024-11-19T04:56:53.220671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ],
   "id": "f6da87557da13aef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:58:44.351516Z",
     "start_time": "2024-11-19T04:58:41.508498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt import generate, text_to_token_ids, token_ids_to_text\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ],
   "id": "8eba85b46276b398",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T04:58:48.340440Z",
     "start_time": "2024-11-19T04:58:48.337640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ],
   "id": "4fd44aeaec6f638b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T05:05:26.910706Z",
     "start_time": "2024-11-19T05:04:36.460834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gpt import generate_text_simple\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)     #1\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))   #2\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()    #3\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)         #1\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []    #1\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):    #2\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()   #3\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()                     #4\n",
    "            optimizer.step()                    #5\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:    #6\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        generate_and_print_sample(                      #7\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()  #1\n",
    "    with torch.no_grad():                              #2\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "            )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))      #1\n",
    "    model.train()\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device\n",
    "    )\n",
    "    val_loss = calc_loss_loader(\n",
    "        val_loader, model, device\n",
    "    )\n",
    "    print(f\"Initial train loss: {train_loss:.3f}\")\n",
    "    print(f\"Initial val loss: {val_loss:.3f}\")"
   ],
   "id": "2fbf0f632e81ce07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train loss: 3.787\n",
      "Initial val loss: 3.817\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T05:15:31.802888Z",
     "start_time": "2024-11-19T05:06:15.012323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader,\n",
    "    optimizer, device, num_epochs,\n",
    "    eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Execution time: {execution_time_minutes:.1f} minutes\")"
   ],
   "id": "46a2e32b92adab5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.501, Val loss 2.485\n",
      "Ep 1 (Step 000005): Train loss 1.063, Val loss 1.112\n",
      "Ep 1 (Step 000010): Train loss 0.834, Val loss 0.986\n",
      "Ep 1 (Step 000015): Train loss 0.947, Val loss 0.939\n",
      "Ep 1 (Step 000020): Train loss 0.899, Val loss 0.929\n",
      "Ep 1 (Step 000025): Train loss 0.725, Val loss 0.890\n",
      "Ep 1 (Step 000030): Train loss 0.714, Val loss 0.872\n",
      "Ep 1 (Step 000035): Train loss 0.698, Val loss 0.849\n",
      "Ep 1 (Step 000040): Train loss 0.689, Val loss 0.835\n",
      "Ep 1 (Step 000045): Train loss 0.704, Val loss 0.822\n",
      "Ep 1 (Step 000050): Train loss 0.631, Val loss 0.814\n",
      "Ep 1 (Step 000055): Train loss 0.708, Val loss 0.803\n",
      "Ep 1 (Step 000060): Train loss 0.650, Val loss 0.784\n",
      "Ep 1 (Step 000065): Train loss 0.611, Val loss 0.764\n",
      "Ep 1 (Step 000070): Train loss 0.597, Val loss 0.756\n",
      "Ep 1 (Step 000075): Train loss 0.523, Val loss 0.758\n",
      "Ep 1 (Step 000080): Train loss 0.563, Val loss 0.745\n",
      "Ep 1 (Step 000085): Train loss 0.588, Val loss 0.732\n",
      "Ep 1 (Step 000090): Train loss 0.689, Val loss 0.723\n",
      "Ep 1 (Step 000095): Train loss 0.676, Val loss 0.715\n",
      "Ep 1 (Step 000100): Train loss 0.491, Val loss 0.705\n",
      "Ep 1 (Step 000105): Train loss 0.567, Val loss 0.696\n",
      "Ep 1 (Step 000110): Train loss 0.583, Val loss 0.695\n",
      "Ep 1 (Step 000115): Train loss 0.566, Val loss 0.688\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The active sentence is 'The chef cooks the meal every day.'<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence\n",
      "Ep 2 (Step 000120): Train loss 0.535, Val loss 0.685\n",
      "Ep 2 (Step 000125): Train loss 0.487, Val loss 0.706\n",
      "Ep 2 (Step 000130): Train loss 0.486, Val loss 0.704\n",
      "Ep 2 (Step 000135): Train loss 0.492, Val loss 0.699\n",
      "Ep 2 (Step 000140): Train loss 0.460, Val loss 0.693\n",
      "Ep 2 (Step 000145): Train loss 0.464, Val loss 0.690\n",
      "Ep 2 (Step 000150): Train loss 0.460, Val loss 0.687\n",
      "Ep 2 (Step 000155): Train loss 0.439, Val loss 0.677\n",
      "Ep 2 (Step 000160): Train loss 0.499, Val loss 0.673\n",
      "Ep 2 (Step 000165): Train loss 0.432, Val loss 0.679\n",
      "Ep 2 (Step 000170): Train loss 0.410, Val loss 0.673\n",
      "Ep 2 (Step 000175): Train loss 0.392, Val loss 0.670\n",
      "Ep 2 (Step 000180): Train loss 0.400, Val loss 0.664\n",
      "Ep 2 (Step 000185): Train loss 0.434, Val loss 0.657\n",
      "Ep 2 (Step 000190): Train loss 0.393, Val loss 0.653\n",
      "Ep 2 (Step 000195): Train loss 0.367, Val loss 0.653\n",
      "Ep 2 (Step 000200): Train loss 0.402, Val loss 0.655\n",
      "Ep 2 (Step 000205): Train loss 0.421, Val loss 0.652\n",
      "Ep 2 (Step 000210): Train loss 0.355, Val loss 0.661\n",
      "Ep 2 (Step 000215): Train loss 0.380, Val loss 0.667\n",
      "Ep 2 (Step 000220): Train loss 0.394, Val loss 0.661\n",
      "Ep 2 (Step 000225): Train loss 0.340, Val loss 0.660\n",
      "Ep 2 (Step 000230): Train loss 0.393, Val loss 0.655\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef prepares the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the opposite of 'soft'?  \n",
      "Execution time: 9.3 minutes\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T05:18:42.440437Z",
     "start_time": "2024-11-19T05:18:42.058111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()                   #1\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)     #2\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ],
   "id": "123ad3e1c887f08a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T05:28:43.702517Z",
     "start_time": "2024-11-19T05:28:38.013233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(123)\n",
    "from gpt import generate\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model = model,\n",
    "        idx = text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=NEW_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(\"Input text:\", input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nGenerated response:\\n>> {response_text.strip()}\\n\")\n",
    "    print(\"-\" * 100)"
   ],
   "id": "d54f541bb51ead2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Generated response:\n",
      ">> The car is as fast as a cheetah.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Generated response:\n",
      ">> The type of cloud typically associated with thunderstorms is a cumulus.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Generated response:\n",
      ">> The author of 'Pride and Prejudice' is George Orwell.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T05:33:32.603674Z",
     "start_time": "2024-11-19T05:30:24.148152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=NEW_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    test_data[1][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ],
   "id": "3b067062d257ebdd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [03:08<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T05:36:27.786234Z",
     "start_time": "2024-11-19T05:36:25.979488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "file_name = f\"{re.sub(r'[ ()]', '', model_name)}-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model state dict saved to {file_name}\")"
   ],
   "id": "6e947a74f732516f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state dict saved to gpt2-medium355M-sft.pth\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a77f20286febe991"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
